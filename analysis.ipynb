{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information:\n",
    "\n",
    "This jupyter notebook is solution of task for data exploration classes. Instructions from lecturer and my solution below.\n",
    "\n",
    "## Instructions:\n",
    "1. Download data set, Global Terrorism Database, from https://www.kaggle.com/START-UMD/gtd\n",
    "2. Take a quick look at the data set. Check what's inside, how the data is structured, and where the data is corrupted (missing values, bad structure, etc).\n",
    "3. Think and create 5 questions to the data. Try to ask yourself what's really interesting in the data set. What's not so obvious. E.g. some trends, patterns, correlations.\n",
    "4. Create a jupyter notebook and use python, numpy, pandas, matplotlib (at least) to provide all the answers to your questions.\n",
    "5. Create a new github repository, and put your jupyter notebook there.\n",
    "6. Create readme.md file as well in your github root directory with all necessary instructions (what is in the repo, what libs are necessary to run the code, where to find data set and where to save it  - this is necessary because the dataset is too big for github repo).\n",
    "7. Provide the necessary documentation and introduction in your notebook using markdown language, at least: data source description, data structure, importing process, data processing process.\n",
    "8. Put some data visualization in your notebook. Sometimes it's much easier to present the answer using a chart rather than numbers\n",
    "9. Check if your notebook run smoothly - use 'Reset & Run All' command from the menu. Save it.\n",
    "10. Export the notebook as HTML as well, and save the file in the repo.\n",
    "11. Do not forget to commit/push all the changes to your repo on hithub.\n",
    "12. Smile :) You did a good job!\n",
    "    \n",
    "\n",
    "### FAQ:\n",
    "1. Can I take a look at different solution provided at kaggle?  Yes, you can. But check more than one solution. Try to understand what the authors are trying to solve, and how could it be used in your project. Try to find really good examples - easy to understand and not so complicated. Remember - you create the notebook as an instruction to someone else! Try to not complicate the process.\n",
    "2. Can I take a look at my friend's solution, that he/she has just put on github? Yes, you can. But it's the smart way of solving the project. I'm sure that you want to be smarter in the next semester - so try to create a better solution and your own one :)\n",
    "3. Jupyter notebook provide R kernel, so can I use R instead? Nope, R sucks. Even if you love R, try to solve the project using Python.\\n\n",
    "\n",
    "## Solution:\n",
    "\n",
    "### Created questions: \n",
    "1. How the frequency of terrorist attacks has changed over the years? \n",
    "2. In which regions, countries, cities there was the most attack?\n",
    "3. Most popular attacking methods?\n",
    "4. What was the most favorite targets?\n",
    "5. What was most popular attack types in regions?\n",
    "6. How many people died in attacks? \n",
    "7. Which attack type is most \"efficient\"? \n",
    "8. What are most active terror organizations? \n",
    "\n",
    "### Table of Contents\n",
    "1. [Imports](#imports)\n",
    "2. [Get data ready](#data)\n",
    "3. [Terrorism over the years](#over_years)\n",
    "4. [Terrorist activities in regions](#regions)\n",
    "5. [Most popular attacking methods](#methods)\n",
    "6. [Most popular attack types in regions](#types)\n",
    "7. [Most favorite targets](#targets)\n",
    "8. [How many people died in attacks](#deaths) \n",
    "9. [Most active terror organizations](#activity)\n",
    "10. [Popular crime motives](#motive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports  <a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/xavier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/xavier/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_scalar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-65340706e817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Venvs/gtan/lib/python3.6/site-packages/mpl_toolkits/basemap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_matplotlib_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdedent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# check to make sure matplotlib is not too old.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0m_matplotlib_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_matplotlib_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_scalar'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get data ready  <a name=\"data\"></a>\n",
    "\n",
    "Db import with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'globalterrorismdb_0718dist.csv'\n",
    "db = pd.read_csv(db_path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After simple filtering lets take a very first look at out DB. The results are presented in the table below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.rename(columns = {'iyear':'Year','imonth':'Month','iday':'Day','country_txt':'Country','region_txt':'Region',\n",
    "                     'attacktype1_txt':'AttackType','target1':'Target','nkill':'Killed','nwound':'Wounded',\n",
    "                     'summary':'Summary','gname':'Group','targtype1_txt':'Target_type','weaptype1_txt':'Weapon_type',\n",
    "                     'motive':'Motive'},inplace=True)\n",
    "db_filtered = db[['Year','Month','Day','Country','Region','city','latitude','longitude','AttackType','Killed',\n",
    "                  'Wounded','Target','Summary','Group','Target_type','Weapon_type','Motive']]\n",
    "db_filtered['Casualities'] = db_filtered['Killed'] + db_filtered['Wounded']\n",
    "db_filtered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Terrorism over the years  <a name=\"over_years\"></a>\n",
    "\n",
    "Let's see how the frequency of terrorist attacks has changed over the years!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_years = pd.DataFrame({'Year':db_filtered['Year'].unique(), 'Freq': db_filtered['Year'].value_counts().sort_index()})\n",
    "\n",
    "plt.subplots(figsize=(15,6))\n",
    "sns.lineplot(x='Year', y='Freq', data=over_years, marker='o', palette='inferno')\n",
    "plt.xticks(over_years['Year'], rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Counts', fontsize=14)\n",
    "plt.title('Number Of Terrorist Activities Each Year (missing data for 1993)', fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly growth of terrorist activities after 2011. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Terrorist activities in regions  <a name=\"regions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,6))\n",
    "sns.countplot('Region', data=db_filtered)\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Region', fontsize=14)\n",
    "plt.ylabel('Counts', fontsize=14)\n",
    "plt.title('Number Of Terrorist Activities By Region', fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regions where are the most terrorism acts are Middle East and North Africa followed by South Asia. Australasian & Oceania region seems to be most peaceful place to live. \n",
    "\n",
    "Now let's take a look on top 10 dangerous countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,6))\n",
    "sns.barplot(db_filtered['Country'].value_counts()[:10].index, \n",
    "            db_filtered['Country'].value_counts()[:10].values,\n",
    "            palette='inferno')\n",
    "plt.xticks(rotation=90, fontsize=1)\n",
    "plt.xlabel('Country', fontsize=14)\n",
    "plt.ylabel('Counts', fontsize=14)\n",
    "plt.title('Number Of Terrorist Activities By Country', fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could have foreseen most dangerous are Middle East countries. It is interesting that the US is not in the top 10 dangerous countries. \n",
    "\n",
    "We should check how activity in regions has been changing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terror_region=pd.crosstab(db_filtered['Year'],db_filtered['Region'])\n",
    "terror_region.plot(color=sns.color_palette('Set2',12),  fontsize=14)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(18,6)\n",
    "plt.title('Terrorism attacks over years in World\\'s regions', fontsize=14)\n",
    "plt.ylabel('Counts', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a global look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = Basemap(projection='mill',llcrnrlat=-80,urcrnrlat=80, llcrnrlon=-180,urcrnrlon=180,lat_ts=20,resolution='c',lat_0=True,lat_1=True)\n",
    "lat_100=list(db_filtered[db_filtered['Casualities']>=75].latitude)\n",
    "long_100=list(db_filtered[db_filtered['Casualities']>=75].longitude)\n",
    "x_100,y_100=m3(long_100,lat_100)\n",
    "m3.plot(x_100, y_100,'go',markersize=5,color = 'r')\n",
    "lat_=list(db_filtered[db_filtered['Casualities']<75].latitude)\n",
    "long_=list(db_filtered[db_filtered['Casualities']<75].longitude)\n",
    "x_,y_=m3(long_,lat_)\n",
    "m3.plot(x_, y_,'go',markersize=2,color = 'b',alpha=0.4)\n",
    "m3.drawcoastlines()\n",
    "m3.drawcountries()\n",
    "m3.fillcontinents(lake_color='gray')\n",
    "m3.drawmapboundary(fill_color='gray')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(14,12)\n",
    "plt.title('Global Terrorist Attacks', fontsize=24)\n",
    "plt.legend(loc='center right',\n",
    "           handles=[mpatches.Patch(color='b', label = \"< 75 casualities\"),\n",
    "                    mpatches.Patch(color='red',label='> 75 casualities')],\n",
    "           bbox_to_anchor=(1, 0, 0.5, 1),\n",
    "           fontsize = 20)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above basemap shows the places of attacks. The red circles are those that had more than 75 casualities(wounded+killed). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Most popular attacking methods <a name=\"methods\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to take a look on most 'popular' attack types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db_filtered['AttackType'].value_counts()\n",
    "labels = db_filtered['AttackType'].value_counts().index\n",
    "colors = plt.cm.inferno(np.linspace(0., 1., len(labels)))\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(aspect=\"equal\"), figsize=(8,8))\n",
    "wedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=-130, colors=colors, shadow=True)\n",
    "ax.legend(handles=wedges, \n",
    "          labels=[f'{l}: {s/data.sum()*100:.2f}%' for l, s in zip(labels, data)], \n",
    "          loc='center left', \n",
    "          bbox_to_anchor=(1, 0, 0.5, 1),\n",
    "          fontsize=12)\n",
    "\n",
    "ax.set_title('Most popular attack types', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main aim of terrorist attacks it's to terrify population. Bombing is the right method for this - not very subtle and not very precise, but effective especially when it comes to terryfing people.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Most popular attack types in regions <a name=\"types\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(db_filtered['Region'],\n",
    "            db_filtered['AttackType'], normalize='index')\\\n",
    ".plot.barh(stacked=True, width=0.9, color=sns.color_palette('RdYlGn',9), fontsize=13)\n",
    "\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(12,10)\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('Regions', fontsize=14)\n",
    "plt.xlabel('Ratio', fontsize=14)\n",
    "plt.title('Attack types ratio in Regions', fontsize=14)\n",
    "plt.legend(bbox_to_anchor=(1, 0, 0.5, 1), fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For almost every region attack types ratio looks similarly. In Central America & Caribbean region arme assault it's more popular than in others, central asians likes assasinations and in North America, Australasia and East Asia there is more hijackings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Most favorite targets <a name=\"targets\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,6))\n",
    "sns.countplot(db_filtered['Target_type'],\n",
    "              palette='inferno',\n",
    "              order=db_filtered['Target_type'].value_counts().index)\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Target types', fontsize=14)\n",
    "plt.ylabel('Counts', fontsize=14)\n",
    "plt.title('Popular Targets', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is foreseeable that private citizens are main target because terrorism is mainly about terrify people.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. How many people died in attacks <a name=\"deaths\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coun_terror=db_filtered['Country'].value_counts()[:15].to_frame()\n",
    "coun_terror.columns=['Attacks']\n",
    "coun_kill=db_filtered.groupby('Country')['Killed'].sum().to_frame()\n",
    "coun_terror.merge(coun_kill,\n",
    "                  left_index=True,\n",
    "                  right_index=True,\n",
    "                  how='left').plot.bar(width=0.9, colors=sns.color_palette('inferno',2))\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(18,6)\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Country', fontsize=14)\n",
    "plt.ylabel('Counts', fontsize=14)\n",
    "plt.title('Number of attacks vs number of deaths', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is terryfing how many people died in Middle East, let's take a look on Iraq, Pakistan, Afganistan... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Most active terror organizations <a name=\"activity\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most notorious organizations\n",
    "\n",
    "sns.barplot(db_filtered['Group'].value_counts()[1:15].values,\n",
    "            db_filtered['Group'].value_counts()[1:15].index,\n",
    "            palette=('inferno'))\n",
    "plt.xticks(rotation=90)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Counts', fontsize=14)\n",
    "plt.ylabel('Organizations', fontsize=14)\n",
    "plt.title('Number of attacks vs number of deaths', fontsize=14)\n",
    "plt.title('Terrorist Groups with Highest Terror Attacks', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can se that most active groupes are connected with religious views - Taliban, ISIL, Al-Shabaab are islam led by Islamic radicals, but there are also some politic based organisations like SL, FMLN or IRA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how groups activity have been changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_groups=db_filtered[db_filtered['Group'].isin(db_filtered['Group'].value_counts()[1:11].index)]\n",
    "pd.crosstab(top_groups.Year,top_groups.Group).plot(color=sns.color_palette('Set1',10))\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(18,6)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.title('Groups activity over the years', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Popular crime motives <a name=\"motive\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end we should take a look on popular terrorism motives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text: str) -> str:\n",
    "    return \" \".join(\n",
    "        __wnl.lemmatize(word, tag[0].lower()) if tag[0].lower() in ['a', 'n', 'v'] else __wnl.lemmatize(word)\n",
    "            for word, tag in pos_tag(word_tokenize(text)))\n",
    "\n",
    "def remove_multispaces(text: str) -> str: return re.sub(r' +', ' ', text)\n",
    "\n",
    "def lowercase(text: str) -> str: return text.lower()\n",
    "\n",
    "def remove_punctuation(text: str) -> str: return re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "\n",
    "def remove_numberwords(text: str) -> str: return re.sub(r'\\w*\\d\\w*', ' ', text)\n",
    "\n",
    "def remove_stopwords(text: str) -> str: return \" \".join(x for x in text.split() if x not in STOP)\n",
    "\n",
    "def remove_numbers(text: str) -> str: return \" \".join(x for x in text.split() if not  x.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motives = db_filtered['Motive'].dropna()\n",
    "motives = motives.apply(lowercase)\n",
    "motives = motives.apply(lemmatize)\n",
    "motives = motives.apply(remove_punctuation)\n",
    "motives = motives.apply(remove_numberwords)\n",
    "motives = motives.apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP = nltk.corpus.stopwords.words('english') + [\"attack\", \"specific\", \"motive\", \"sources\",  \"unknown\", \n",
    "                                                 \"claim\", \"target\", \"carry\", \"note\", \"incident\", \"noor\",\n",
    "                                                 \"state\", \"responsibility\", \"the\", \"illinois\", \"vietnam\", \n",
    "                                                 \"cairo\", \"december\", \"deparment\", \"draft\", \"state\", 'source', 'police']\n",
    "\n",
    "motives = motives.apply(remove_multispaces)\n",
    "motives = motives.apply(remove_stopwords)\n",
    "\n",
    "wordcloud = WordCloud(background_color='white', max_font_size=50, colormap='Dark2', max_words=200)\n",
    "wordcloud.generate(str(motives.values))\n",
    "plt.imshow(wordcloud)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,6)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
